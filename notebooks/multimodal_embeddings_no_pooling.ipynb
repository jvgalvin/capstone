{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441ca1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johngalvin/miniforge3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pydicom\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from PIL import Image\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38b8a65",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "This notebook has the same models as multimodal_embeddings.ipynb, except that instead of pooling 160 of each patient's images into a single vector, we perform feature extraction on the first 20 of each patient's images and feed **all** of them to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf785df",
   "metadata": {},
   "source": [
    "## Generate embeddings for ADNI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d78cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file /Users/johngalvin/Downloads/ADNI 2/068_S_0473/.DS_Store: File is missing DICOM File Meta Information header or the 'DICM' prefix is missing from the header. Use force=True to force reading.\n",
      "Error processing file /Users/johngalvin/Downloads/ADNI 2/068_S_0473/MPRAGE/.DS_Store: File is missing DICOM File Meta Information header or the 'DICM' prefix is missing from the header. Use force=True to force reading.\n",
      "Error processing file /Users/johngalvin/Downloads/ADNI 2/032_S_0677/.DS_Store: File is missing DICOM File Meta Information header or the 'DICM' prefix is missing from the header. Use force=True to force reading.\n",
      "Error processing file /Users/johngalvin/Downloads/ADNI 2/032_S_0677/MPRAGE/.DS_Store: File is missing DICOM File Meta Information header or the 'DICM' prefix is missing from the header. Use force=True to force reading.\n",
      "Error processing file /Users/johngalvin/Downloads/ADNI 2/032_S_0677/MPRAGE/2016-07-22_09_23_31.0/.DS_Store: File is missing DICOM File Meta Information header or the 'DICM' prefix is missing from the header. Use force=True to force reading.\n",
      "Error processing file /Users/johngalvin/Downloads/ADNI 2/068_S_0210/.DS_Store: File is missing DICOM File Meta Information header or the 'DICM' prefix is missing from the header. Use force=True to force reading.\n",
      "Error processing file /Users/johngalvin/Downloads/ADNI 2/068_S_0210/MPRAGE/.DS_Store: File is missing DICOM File Meta Information header or the 'DICM' prefix is missing from the header. Use force=True to force reading.\n",
      "Error processing file /Users/johngalvin/Downloads/ADNI 2/068_S_0210/MPRAGE/2016-11-03_14_21_45.0/.DS_Store: File is missing DICOM File Meta Information header or the 'DICM' prefix is missing from the header. Use force=True to force reading.\n"
     ]
    }
   ],
   "source": [
    "pt_ids = []\n",
    "pixels = []\n",
    "\n",
    "directory_path = '/Users/johngalvin/Downloads/ADNI 2'\n",
    "\n",
    "# Iterate through level 2 subdirectories\n",
    "for level_2_foldername in os.listdir(directory_path):\n",
    "    level_2_folder_path = os.path.join(directory_path, level_2_foldername)\n",
    "    \n",
    "    if os.path.isdir(level_2_folder_path):\n",
    "        # Iterate through DICOM files in level 5 (bottom-most level) of each level 2 folder\n",
    "        for root, _, files in os.walk(level_2_folder_path):\n",
    "            for file in files:\n",
    "                try:\n",
    "                    file_path = os.path.abspath(os.path.join(root, file))\n",
    "                    \n",
    "                    # Attempt to read DICOM file\n",
    "                    dcm = pydicom.dcmread(file_path)\n",
    "                    \n",
    "                    # Check if the file has PixelData (to avoid non-image DICOM files)\n",
    "                    if hasattr(dcm, 'PixelData'):\n",
    "                        # Append both level 2 folder name and pixel array to the lists\n",
    "                        pt_ids.append(file[5:15])\n",
    "                        pixels.append(dcm.pixel_array)\n",
    "                except Exception as e:\n",
    "                    # Handle exceptions (e.g., files without 'TransferSyntaxUID')\n",
    "                    print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "# Create a DataFrame from the lists\n",
    "mri_df = pd.DataFrame({'PTID': pt_ids, 'Pixel Array': pixels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83119559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize image arrays with Bilinear Interpolation\n",
    "resized_arrays = []\n",
    "\n",
    "for val in mri_df[\"Pixel Array\"]:\n",
    "    image = Image.fromarray(val, mode='L')\n",
    "    resized_image = image.resize((224, 224), Image.BILINEAR)\n",
    "    resized_array = np.expand_dims(np.array(resized_image, dtype=np.uint8), axis=-1) #TF expects channel dim\n",
    "    resized_arrays.append(resized_array)\n",
    "    \n",
    "mri_df[\"Pixel Array\"] = resized_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22814860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep just the first 20 images for each patient (size/speed)\n",
    "mri_df = mri_df.groupby(\"PTID\").head(20)\n",
    "mri_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "883549c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 3 channels for VGG16 (num_samples, 224, 224, 3) - after running this cell\n",
    "resized_arrays = []\n",
    "\n",
    "for i in range(len(mri_df[\"Pixel Array\"])):\n",
    "    resized_arrays.append(np.repeat(mri_df[\"Pixel Array\"][i], 3, axis=-1))\n",
    "    \n",
    "mri_df[\"Pixel Array\"] = resized_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37dfb361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in med/famhist\n",
    "mf_hist = pd.read_csv('../data/clinical_training_data_with_medhist_famhist.csv')\n",
    "\n",
    "# Handle Nan\n",
    "mf_hist[\"Family_History_of_AD\"] = mf_hist[\"Family_History_of_AD\"].fillna(0)\n",
    "mf_hist[\"Family_History_of_Dementia\"] = mf_hist[\"Family_History_of_Dementia\"].fillna(0)\n",
    "\n",
    "# For converting categorical variables to ints\n",
    "label_encoder = LabelEncoder()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Split features / target\n",
    "X = mf_hist.drop(columns=['AD_dx_in_5_yrs'])\n",
    "y = mf_hist['AD_dx_in_5_yrs']\n",
    "\n",
    "# Encode features\n",
    "X[\"Diagnosis_at_Baseline\"] = label_encoder.fit_transform(X[\"Diagnosis_at_Baseline\"])\n",
    "X[\"Gender\"] = label_encoder.fit_transform(X[\"Gender\"])\n",
    "X[\"Ethnicity\"] = label_encoder.fit_transform(X[\"Ethnicity\"])\n",
    "X[\"Race\"] = label_encoder.fit_transform(X[\"Race\"])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b5205c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale pixel data\n",
    "train_unscaled_mri_df = pd.merge(mri_df, X_train[[\"PTID\"]], on=\"PTID\", how=\"inner\")\n",
    "test_unscaled_mri_df = pd.merge(mri_df, X_test[[\"PTID\"]], on=\"PTID\", how=\"inner\")\n",
    "\n",
    "train_unscaled_arrays = np.array(train_unscaled_mri_df[\"Pixel Array\"].tolist())\n",
    "test_unscaled_arrays = np.array(test_unscaled_mri_df[\"Pixel Array\"].tolist())\n",
    "\n",
    "mean = np.mean(train_unscaled_arrays, axis=(0, 1, 2))\n",
    "std = np.std(train_unscaled_arrays, axis=(0, 1, 2))\n",
    "\n",
    "train_scaled_array = (train_unscaled_arrays - mean) / std\n",
    "test_scaled_array = (test_unscaled_arrays - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2830793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder labels (order changed when forming unscaled_mri_df)\n",
    "y_train_final = []\n",
    "for val in train_unscaled_mri_df[\"PTID\"].value_counts().index.values:\n",
    "    y_train_final.append(mf_hist.loc[mf_hist[\"PTID\"] == val, \"AD_dx_in_5_yrs\"].values[0])\n",
    "y_train_final = np.array(y_train_final)\n",
    "\n",
    "y_test_final = []\n",
    "for val in test_unscaled_mri_df[\"PTID\"].value_counts().index.values:\n",
    "    y_test_final.append(mf_hist.loc[mf_hist[\"PTID\"] == val, \"AD_dx_in_5_yrs\"].values[0])\n",
    "y_test_final = np.array(y_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97cb6e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [23.53734755 23.53734755 23.53734755]\n",
      "STD: [31.01920724 31.01920724 31.01920724]\n"
     ]
    }
   ],
   "source": [
    "print (f'Mean: {mean}')\n",
    "print (f'STD: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7014d352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 11:21:19.517396: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-11 11:21:19.517445: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "feature_extractor = tf.keras.models.load_model(\"feature_extractor/feature_extractor_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287400f",
   "metadata": {},
   "source": [
    "## Generate embeddings and pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80c49b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings and pool\n",
    "patient_ids = []\n",
    "latent_reps = []\n",
    "\n",
    "start = 0\n",
    "end = 20\n",
    "for i in range(len(train_unscaled_mri_df[\"PTID\"].value_counts().index.values)):\n",
    "    p_id = train_unscaled_mri_df[\"PTID\"].value_counts().index.values[i]\n",
    "    patient_ids.append(p_id)\n",
    "    features = feature_extractor(train_scaled_array[start:end]).numpy() # Each patient has 20 images (20, 512)\n",
    "    #latent_rep = np.mean(np.stack(features, axis=-1), axis=1) # (512,), max pooling\n",
    "    latent_rep = features.flatten()\n",
    "    latent_reps.append(latent_rep)\n",
    "    start += 20\n",
    "    end += 20\n",
    "\n",
    "train_embeddings = pd.DataFrame()\n",
    "train_embeddings[\"PTID\"] = patient_ids\n",
    "train_embeddings[\"embedding\"] = latent_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e01ab22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings and pool\n",
    "patient_ids = []\n",
    "latent_reps = []\n",
    "\n",
    "start = 0\n",
    "end = 20\n",
    "for i in range(len(test_unscaled_mri_df[\"PTID\"].value_counts().index.values)):\n",
    "    p_id = test_unscaled_mri_df[\"PTID\"].value_counts().index.values[i]\n",
    "    patient_ids.append(p_id)\n",
    "    features = feature_extractor(test_scaled_array[start:end]).numpy() # Each patient has 160 images (20, 512)\n",
    "    #latent_rep = np.mean(np.stack(features, axis=-1), axis=1) # (512,), max pooling\n",
    "    latent_rep = features.flatten()\n",
    "    latent_reps.append(latent_rep)\n",
    "    start += 20\n",
    "    end += 20\n",
    "\n",
    "test_embeddings = pd.DataFrame()\n",
    "test_embeddings[\"PTID\"] = patient_ids\n",
    "test_embeddings[\"embedding\"] = latent_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f9e90bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join back into X_train, X_test\n",
    "X_train = pd.merge(train_embeddings, X_train, on=\"PTID\")\n",
    "X_test = pd.merge(test_embeddings, X_test, on=\"PTID\")\n",
    "\n",
    "# Scale remaining data (clinical/genetic)\n",
    "embedding_column_train = X_train[\"embedding\"]\n",
    "embedding_column_test = X_test[\"embedding\"]\n",
    "\n",
    "columns_to_scale_train = X_train.drop(columns=[\"embedding\", \"PTID\"])\n",
    "columns_to_scale_test = X_test.drop(columns=[\"embedding\", \"PTID\"])\n",
    "\n",
    "scaled_train = scaler.fit_transform(columns_to_scale_train)\n",
    "scaled_test = scaler.transform(columns_to_scale_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(data=scaled_train, columns=columns_to_scale_train.columns)\n",
    "X_test_scaled = pd.DataFrame(data=scaled_test, columns=columns_to_scale_test.columns)\n",
    "\n",
    "X_train_scaled[\"embedding\"] = embedding_column_train\n",
    "X_test_scaled[\"embedding\"] = embedding_column_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9a091cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_scaled, y_train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e8f9a",
   "metadata": {},
   "source": [
    "## Concatenate embedding with clinical/genetic feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad7f6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure for training\n",
    "vector_column = X_train_resampled[\"embedding\"].values\n",
    "other_columns = X_train_resampled.drop(columns=[\"embedding\"]).values\n",
    "X_train_final = np.hstack((other_columns, np.vstack(vector_column)))\n",
    "\n",
    "# Structure for test\n",
    "vector_column = X_test_scaled[\"embedding\"].values\n",
    "other_columns = X_test_scaled.drop(columns=[\"embedding\"]).values\n",
    "X_test_final = np.hstack((other_columns, np.vstack(vector_column)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7491ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_FEATURES = X_train_final[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9880011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dropout=0.3, learning_rate=0.0001, l2_penalty=0.1):\n",
    "    \"\"\"Builds classification model\"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    inputs = tf.keras.layers.Input(shape=(IN_FEATURES,), name=\"input_layer\") # (Batch, num_features)\n",
    "    \n",
    "    hidden_1 = tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2_penalty), name=\"hidden_1\")(inputs)\n",
    "    hidden_1 = tf.keras.layers.Dropout(dropout)(hidden_1)\n",
    "    hidden_2 = tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2_penalty), name=\"hidden_2\")(hidden_1)\n",
    "    hidden_2 = tf.keras.layers.Dropout(dropout)(hidden_2)\n",
    "    \n",
    "    classification = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"classification_layer\")(hidden_1)\n",
    "    classification_model = tf.keras.Model(inputs=[inputs], outputs=[classification])\n",
    "    \n",
    "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "                                 metrics=\"accuracy\")\n",
    "\n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bb04648",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05da5fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 45.0726 - accuracy: 0.5529\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 34.4453 - accuracy: 0.6059\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 26.1435 - accuracy: 0.6471\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 19.8390 - accuracy: 0.6441\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 14.9985 - accuracy: 0.6971\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 11.3780 - accuracy: 0.7029\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 8.6497 - accuracy: 0.7118\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 6.6046 - accuracy: 0.7235\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 5.0898 - accuracy: 0.7706\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 3.9813 - accuracy: 0.7618\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 3.1677 - accuracy: 0.7706\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 2.5795 - accuracy: 0.7824\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 2.1384 - accuracy: 0.7941\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 1.8101 - accuracy: 0.8059\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 1.5865 - accuracy: 0.8088\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 1.3972 - accuracy: 0.8353\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 1.2856 - accuracy: 0.7941\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 1.2157 - accuracy: 0.7735\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 1.1028 - accuracy: 0.8206\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 1.0819 - accuracy: 0.7706\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.9927 - accuracy: 0.8176\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.9612 - accuracy: 0.8176\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.9078 - accuracy: 0.8529\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.9249 - accuracy: 0.7441\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.8520 - accuracy: 0.8588\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.8796 - accuracy: 0.7765\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.8464 - accuracy: 0.7765\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.7859 - accuracy: 0.8588\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.7704 - accuracy: 0.8588\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.7654 - accuracy: 0.8441\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.7558 - accuracy: 0.8324\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.7199 - accuracy: 0.8647\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.7269 - accuracy: 0.8559\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.7265 - accuracy: 0.8412\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.6927 - accuracy: 0.8794\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.6840 - accuracy: 0.8794\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.6743 - accuracy: 0.8853\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.6659 - accuracy: 0.8971\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6535 - accuracy: 0.8676\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.6452 - accuracy: 0.8500\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.6580 - accuracy: 0.8529\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.6576 - accuracy: 0.8471\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6272 - accuracy: 0.8765\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6249 - accuracy: 0.8735\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.6136 - accuracy: 0.8706\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5970 - accuracy: 0.8882\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.6071 - accuracy: 0.8794\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 0.5977 - accuracy: 0.8853\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5991 - accuracy: 0.8794\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.6753 - accuracy: 0.7441\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.6148 - accuracy: 0.8176\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5725 - accuracy: 0.8941\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5916 - accuracy: 0.8647\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5899 - accuracy: 0.8353\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5758 - accuracy: 0.8706\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5761 - accuracy: 0.8765\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5762 - accuracy: 0.8647\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5808 - accuracy: 0.8647\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5779 - accuracy: 0.8618\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5704 - accuracy: 0.8676\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5725 - accuracy: 0.8529\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5815 - accuracy: 0.8441\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5522 - accuracy: 0.8706\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5448 - accuracy: 0.8882\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5742 - accuracy: 0.8412\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5706 - accuracy: 0.8324\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5464 - accuracy: 0.8529\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5480 - accuracy: 0.8853\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.5255 - accuracy: 0.9059\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5211 - accuracy: 0.9147\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5203 - accuracy: 0.9000\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5286 - accuracy: 0.8853\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5417 - accuracy: 0.8735\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5258 - accuracy: 0.8882\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5156 - accuracy: 0.9088\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5355 - accuracy: 0.8853\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5107 - accuracy: 0.9029\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5180 - accuracy: 0.8794\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5244 - accuracy: 0.8853\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5192 - accuracy: 0.8794\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5178 - accuracy: 0.8882\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5037 - accuracy: 0.9000\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5056 - accuracy: 0.9147\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5033 - accuracy: 0.9059\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5092 - accuracy: 0.8824\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5342 - accuracy: 0.8382\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5506 - accuracy: 0.8412\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5347 - accuracy: 0.8529\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.4993 - accuracy: 0.8941\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5032 - accuracy: 0.9059\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.4884 - accuracy: 0.8971\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.4873 - accuracy: 0.8971\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5080 - accuracy: 0.8853\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.4979 - accuracy: 0.8706\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5306 - accuracy: 0.8500\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.4845 - accuracy: 0.8941\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5021 - accuracy: 0.8824\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.5589 - accuracy: 0.8353\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.5382 - accuracy: 0.8500\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.4955 - accuracy: 0.8882\n"
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "history = model.fit(X_train_final,\n",
    "                    y_train_resampled,\n",
    "                    #validation_data=[X_test_final, y_test_final],\n",
    "                    batch_size=16,\n",
    "                    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64c282dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 43ms/step - loss: 0.7770 - accuracy: 0.6825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7770423889160156, 0.682539701461792]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_final, y_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08f5aac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If simply guessing all 0, can get this accuracy: 0.746031746031746\n"
     ]
    }
   ],
   "source": [
    "print (\"If simply guessing all 0, can get this accuracy:\", 1 - y_test_final.sum() / y_test_final.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7743615",
   "metadata": {},
   "source": [
    "# Try SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6151833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a319cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5aa5c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 10],                \n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\": [\"scale\", \"auto\", 0.1],\n",
    "    \"degree\": [1, 2, 3, 4, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6210afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "990f874a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'degree': [1, 2, 3, 4, 5],\n",
       "                         'gamma': ['scale', 'auto', 0.1],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train_final, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "97f5390e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'degree': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best Accuracy: 0.9147058823529411\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters and best accuracy score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8aeefe0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, degree=1, gamma=0.1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit model\n",
    "svc = SVC(C=1, degree=1, gamma=0.1, kernel=\"rbf\")\n",
    "\n",
    "svc.fit(X_train_final, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d9194cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.85        47\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.75        63\n",
      "   macro avg       0.37      0.50      0.43        63\n",
      "weighted avg       0.56      0.75      0.64        63\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johngalvin/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/johngalvin/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/johngalvin/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Assess\n",
    "y_pred = svc.predict(X_test_final)\n",
    "\n",
    "# evaluate predictions\n",
    "print(classification_report(y_test_final, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02515fd5",
   "metadata": {},
   "source": [
    "# What if we do image-only?\n",
    "\n",
    "Note: this model below accepts the pooled embeddings formed after VGG16 feature extraction. The only difference from above is that it does **not** concatenate each final pooled embedding with the clinical/genetic feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a794380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img_only = np.vstack(X_train_scaled[\"embedding\"])\n",
    "y_train_img_only = y_train_final\n",
    "\n",
    "X_test_img_only = np.vstack(X_test_scaled[\"embedding\"])\n",
    "y_test_img_only = y_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d634de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dropout=0.3, learning_rate=0.0001):\n",
    "    \"\"\"Builds classification model\"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    inputs = tf.keras.layers.Input(shape=(10240,), name=\"input_layer\") # (Batch, num_features)\n",
    "    \n",
    "    hidden_1 = tf.keras.layers.Dense(512, activation=\"relu\", name=\"hidden_1\")(inputs)\n",
    "    hidden_1 = tf.keras.layers.Dropout(dropout)(hidden_1)\n",
    "    hidden_2 = tf.keras.layers.Dense(256, activation=\"relu\", name=\"hidden_2\")(hidden_1)\n",
    "    hidden_2 = tf.keras.layers.Dropout(dropout)(hidden_2)\n",
    "    \n",
    "    classification = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"classification_layer\")(hidden_2)\n",
    "    classification_model = tf.keras.Model(inputs=[inputs], outputs=[classification])\n",
    "    \n",
    "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "                                 metrics=\"accuracy\")\n",
    "\n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7823ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_only_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92af560f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 3/16 [====>.........................] - ETA: 0s - loss: 0.7891 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johngalvin/miniforge3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "/Users/johngalvin/miniforge3/lib/python3.9/site-packages/keras/backend.py:5676: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 30ms/step - loss: 0.7068 - accuracy: 0.6194 - val_loss: 0.5726 - val_accuracy: 0.7460\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.6386 - accuracy: 0.6640 - val_loss: 0.5837 - val_accuracy: 0.7460\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.6211 - accuracy: 0.6883 - val_loss: 0.6174 - val_accuracy: 0.7302\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.5979 - accuracy: 0.6721 - val_loss: 0.5738 - val_accuracy: 0.7460\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.6007 - accuracy: 0.6761 - val_loss: 0.6881 - val_accuracy: 0.4921\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.5940 - accuracy: 0.6802 - val_loss: 0.5886 - val_accuracy: 0.7460\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.5553 - accuracy: 0.7287 - val_loss: 0.5814 - val_accuracy: 0.7460\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.5284 - accuracy: 0.7328 - val_loss: 0.6056 - val_accuracy: 0.7460\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.5188 - accuracy: 0.7287 - val_loss: 0.6181 - val_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.4915 - accuracy: 0.7773 - val_loss: 0.6064 - val_accuracy: 0.7460\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.5000 - accuracy: 0.7490 - val_loss: 0.6285 - val_accuracy: 0.6508\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.4714 - accuracy: 0.7895 - val_loss: 0.6189 - val_accuracy: 0.7302\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.4418 - accuracy: 0.8057 - val_loss: 0.6398 - val_accuracy: 0.6667\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.4691 - accuracy: 0.7733 - val_loss: 0.6266 - val_accuracy: 0.6984\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.4393 - accuracy: 0.8097 - val_loss: 0.6329 - val_accuracy: 0.7143\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.3943 - accuracy: 0.8502 - val_loss: 0.6411 - val_accuracy: 0.6825\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.3840 - accuracy: 0.8340 - val_loss: 0.6639 - val_accuracy: 0.7143\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.3854 - accuracy: 0.8381 - val_loss: 0.6852 - val_accuracy: 0.7302\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.3390 - accuracy: 0.8623 - val_loss: 0.6938 - val_accuracy: 0.6984\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.3558 - accuracy: 0.8462 - val_loss: 0.6990 - val_accuracy: 0.7302\n"
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "img_only_history = img_only_model.fit(X_train_img_only,\n",
    "                                      y_train_img_only,\n",
    "                                      validation_data=[X_test_img_only, y_test_img_only],\n",
    "                                      batch_size=16,\n",
    "                                      epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f78a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
